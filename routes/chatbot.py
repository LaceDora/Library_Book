from flask import Blueprint, request, jsonify
import google.generativeai as genai
import chromadb
from chromadb.utils import embedding_functions
from dotenv import load_dotenv
import os
import logging
from models import Book, db

# Load environment variables
load_dotenv()

# Configure Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Blueprint
chatbot = Blueprint('chatbot_bp', __name__)

# Configuration
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
CHROMA_DB_PATH = "./chroma_db"
COLLECTION_NAME = "library_books"
EMBEDDING_MODEL = "models/text-embedding-004"
CHAT_MODEL = "gemini-2.0-flash-lite"

# Initialize Gemini
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
else:
    logger.error("GOOGLE_API_KEY not found in environment variables")

# Initialize ChromaDB
try:
    chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    
    # Custom Embedding Function using Gemini API
    class GeminiEmbeddingFunction(embedding_functions.EmbeddingFunction):
        def __call__(self, input: list[str]) -> list[list[float]]:
            try:
                # Gemini API expects 'content' for embed_content, handling batching if needed
                # But for simplicity, we loop or use batch method if available.
                # The SDK supports batch embedding via embed_content(..., content=list)
                result = genai.embed_content(
                    model=EMBEDDING_MODEL,
                    content=input,
                    task_type="retrieval_document" # or retrieval_query depending on usage
                )
                return result['embedding']
            except Exception as e:
                logger.error(f"Error generating embeddings: {e}")
                return [[] for _ in input] # Return empty on error to avoid crash

    # Use our custom embedding function
    embedding_func = GeminiEmbeddingFunction()
    
    collection = chroma_client.get_or_create_collection(
        name=COLLECTION_NAME,
        embedding_function=embedding_func
    )
    logger.info(f"ChromaDB collection '{COLLECTION_NAME}' loaded. Count: {collection.count()}")

except Exception as e:
    logger.error(f"Failed to initialize ChromaDB: {e}")
    collection = None


def build_index():
    """Re-index all books from MySQL to ChromaDB"""
    if not collection:
        return False, "ChromaDB not initialized"
    
    try:
        # Fetch all active books
        books = Book.query.filter_by(is_active=True).all()
        
        if not books:
            return True, "No books to index"

        ids = []
        documents = []
        metadatas = []

        for book in books:
            # Create a rich text representation for embedding
            # Include Title, Author, Category, and Description
            text_content = f"T·ª±a s√°ch: {book.title}. T√°c gi·∫£: {book.author}. Th·ªÉ lo·∫°i: {book.category}. M√¥ t·∫£: {book.description or 'Kh√¥ng c√≥ m√¥ t·∫£'}."
            
            ids.append(str(book.id))
            documents.append(text_content)
            metadatas.append({
                "title": book.title,
                "author": book.author,
                "category": book.category or "",
                "available_quantity": book.available_quantity or 0,
                "id": book.id
            })

        # Add to ChromaDB (upsert overwrites existing IDs)
        # Process in batches to avoid API limits if necessary, but for small library it's fine
        collection.upsert(
            ids=ids,
            documents=documents,
            metadatas=metadatas
        )
        
        return True, f"Indexed {len(books)} books successfully"
    except Exception as e:
        logger.error(f"Indexing failed: {e}")
        return False, str(e)


def get_rag_context(query_text, n_results=5):
    """Retrieve relevant books using Hybrid Approach (SQL + Vector Search)"""
    
    # 1. Keyword/Category Detection for "List All" queries
    query_lower = query_text.lower()
    
    # Map keywords to DB categories
    category_map = {
        'l·∫≠p tr√¨nh': 'L·∫≠p tr√¨nh',
        'c√¥ng ngh·ªá': 'L·∫≠p tr√¨nh',
        'code': 'L·∫≠p tr√¨nh',
        '√¢m nh·∫°c': '√Çm nh·∫°c',
        'nh·∫°c': '√Çm nh·∫°c',
        'truy·ªán tranh': 'Truy·ªán tranh',
        'manga': 'Truy·ªán tranh',
        'y h·ªçc': 'Y h·ªçc',
        's·ª©c kh·ªèe': 'Y h·ªçc',
        't√¢m l√Ω': 'T√¢m l√Ω'
    }
    
    # Check if user wants to list books by category
    target_category = None
    for key, val in category_map.items():
        if key in query_lower:
            target_category = val
            break
            
    is_list_request = any(w in query_lower for w in ['t·∫•t c·∫£', 'danh s√°ch', 'li·ªát k√™', 'nh·ªØng cu·ªën', 'c√°c cu·ªën'])
    
    # --- STRATEGY A: SQL Category Search (High Precision for Lists) ---
    if target_category and is_list_request:
        try:
            books = Book.query.filter(
                Book.category == target_category, 
                Book.is_active == True
            ).all()
            
            if books:
                context_parts = [f"üìö **Danh s√°ch s√°ch thu·ªôc th·ªÉ lo·∫°i {target_category}:**"]
                for i, book in enumerate(books):
                    status = "‚úÖ C√≤n s·∫µn" if (book.available_quantity or 0) > 0 else "‚ùå H·∫øt s√°ch"
                    context_parts.append(f"{i+1}. **{book.title}**")
                    context_parts.append(f"   - T√°c gi·∫£: {book.author}")
                    context_parts.append(f"   - S·ªë l∆∞·ª£ng: {book.available_quantity or 0} ({status})")
                    context_parts.append("---")
                return "\n".join(context_parts)
        except Exception as e:
            logger.error(f"SQL Category search failed: {e}")
            # Fallback to Vector Search if SQL fails

    # --- STRATEGY B: Specific Title Match (High Precision for specific books) ---
    # Since the library is small, we can check if any book title appears in the query
    try:
        # Get all titles to check against query
        all_books = Book.query.filter_by(is_active=True).all()
        found_specific_books = []
        
        for book in all_books:
            # Check if title is in query (case insensitive)
            if book.title.lower() in query_lower:
                found_specific_books.append(book)
        
        if found_specific_books:
            context_parts = ["üìö **Th√¥ng tin chi ti·∫øt s√°ch b·∫°n h·ªèi:**"]
            for book in found_specific_books:
                status = "‚úÖ C√≤n s·∫µn" if (book.available_quantity or 0) > 0 else "‚ùå H·∫øt s√°ch"
                context_parts.append(f"**{book.title}**")
                context_parts.append(f"- T√°c gi·∫£: {book.author}")
                context_parts.append(f"- Th·ªÉ lo·∫°i: {book.category}")
                context_parts.append(f"- S·ªë l∆∞·ª£ng: {book.available_quantity or 0} ({status})")
                context_parts.append(f"- L∆∞·ª£t xem: {book.views_count or 0}")
                context_parts.append(f"- M√¥ t·∫£: {book.description or 'Kh√¥ng c√≥ m√¥ t·∫£'}")
                context_parts.append("---")
            
            # If we found specific books, we can return immediately or combine with RAG
            # Returning immediately is safer to avoid noise
            return "\n".join(context_parts)
            
    except Exception as e:
        logger.error(f"Specific Title Match failed: {e}")

    # --- STRATEGY C: Vector Search (Semantic Search) ---
    if not collection:
        return ""
    
    try:
        # Query ChromaDB
        results = collection.query(
            query_texts=[query_text],
            n_results=n_results
        )
        
        # Format results
        context_parts = ["üìö **S√°ch li√™n quan t√¨m th·∫•y trong th∆∞ vi·ªán:**"]
        
        if not results['documents'] or not results['documents'][0]:
            return "Kh√¥ng t√¨m th·∫•y s√°ch n√†o li√™n quan trong c∆° s·ªü d·ªØ li·ªáu."

        for i, doc in enumerate(results['documents'][0]):
            meta = results['metadatas'][0][i]
            book_id = meta['id']
            
            # Fetch real-time quantity and views from DB
            real_time_qty = 0
            real_time_views = 0
            try:
                book = Book.query.get(book_id)
                if book:
                    real_time_qty = book.available_quantity or 0
                    real_time_views = book.views_count or 0
            except Exception as e:
                logger.error(f"Error fetching real-time data for book {book_id}: {e}")
                real_time_qty = meta.get('available_quantity', 0)

            status = "‚úÖ C√≤n s·∫µn" if real_time_qty > 0 else "‚ùå H·∫øt s√°ch"
            
            context_parts.append(f"{i+1}. **{meta['title']}**")
            context_parts.append(f"   - T√°c gi·∫£: {meta['author']}")
            context_parts.append(f"   - Th·ªÉ lo·∫°i: {meta['category']}")
            context_parts.append(f"   - T√¨nh tr·∫°ng: {real_time_qty} quy·ªÉn ({status})")
            context_parts.append(f"   - L∆∞·ª£t xem: {real_time_views}")
            context_parts.append(f"   - N·ªôi dung: {doc}") 
            context_parts.append("---")
            
        return "\n".join(context_parts)
        
    except Exception as e:
        logger.error(f"RAG retrieval failed: {e}")
        return ""


def get_ai_response(user_message):
    """Generate response using Gemini with RAG context"""
    try:
        # 1. Get Context via RAG
        context = get_rag_context(user_message)
        
        # 2. Construct System Prompt
        system_instruction = """B·∫°n l√† tr·ª£ l√Ω ·∫£o th√¥ng minh c·ªßa th∆∞ vi·ªán. Nhi·ªám v·ª• c·ªßa b·∫°n l√† h·ªó tr·ª£ ng∆∞·ªùi d√πng t√¨m ki·∫øm s√°ch v√† gi·∫£i ƒë√°p th·∫Øc m·∫Øc v·ªÅ th∆∞ vi·ªán.

H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
1. D·ª±a CH·ª¶ Y·∫æU v√†o th√¥ng tin ƒë∆∞·ª£c cung c·∫•p trong ph·∫ßn 'TH√îNG TIN T·ª™ TH∆Ø VI·ªÜN' d∆∞·ªõi ƒë√¢y.
2. N·∫øu s√°ch c√≥ tr·∫°ng th√°i 'C√≤n s·∫µn' (>0), h√£y b√°o cho ng∆∞·ªùi d√πng bi·∫øt l√† c√≥ th·ªÉ m∆∞·ª£n.
3. N·∫øu s√°ch 'H·∫øt s√°ch' (0), h√£y th√¥ng b√°o hi·ªán t·∫°i ƒë√£ h·∫øt.
4. Khi cung c·∫•p th√¥ng tin CHI TI·∫æT v·ªÅ m·ªôt cu·ªën s√°ch c·ª• th·ªÉ, B·∫ÆT BU·ªòC ph·∫£i ƒë·ªÅ c·∫≠p:
   - T√™n s√°ch
   - T√°c gi·∫£
   - Th·ªÉ lo·∫°i
   - S·ªë l∆∞·ª£ng c√≤n l·∫°i
   - **L∆Ø·ª¢T XEM** (views_count) - KH√îNG ƒê∆Ø·ª¢C B·ªé QUA th√¥ng tin n√†y
5. N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin trong ng·ªØ c·∫£nh, h√£y n√≥i kh√©o l√† b·∫°n kh√¥ng t√¨m th·∫•y s√°ch ƒë√≥ trong th∆∞ vi·ªán, nh∆∞ng c√≥ th·ªÉ ƒë·ªÅ xu·∫•t c√°c s√°ch kh√°c n·∫øu c√≥ trong danh s√°ch.
6. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch, th√¢n thi·ªán, s·ª≠ d·ª•ng ti·∫øng Vi·ªát t·ª± nhi√™n.
7. KH√îNG b·ªãa ƒë·∫∑t th√¥ng tin s√°ch kh√¥ng c√≥ trong ng·ªØ c·∫£nh.

TH√îNG TIN T·ª™ TH∆Ø VI·ªÜN:
"""
        
        # 3. Call Gemini API
        model = genai.GenerativeModel(
            model_name=CHAT_MODEL,
            system_instruction=system_instruction
        )
        
        # Combine context and user message
        full_prompt = f"{context}\n\nC√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {user_message}"
        
        response = model.generate_content(full_prompt)
        return response.text
        
    except Exception as e:
        logger.error(f"AI Generation failed: {e}")
        return "Xin l·ªói, h·ªá th·ªëng ƒëang g·∫∑p s·ª± c·ªë khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n."


# --- Routes ---

@chatbot.route('/chat', methods=['POST'])
def chat():
    data = request.get_json()
    message = data.get('message')
    
    if not message:
        return jsonify({'error': 'No message provided'}), 400
        
    response_text = get_ai_response(message)
    return jsonify({'reply': response_text})


@chatbot.route('/rag/index', methods=['POST'])
def trigger_indexing():
    """Manually trigger re-indexing of books"""
    success, msg = build_index()
    if success:
        return jsonify({'status': 'success', 'message': msg})
    else:
        return jsonify({'status': 'error', 'message': msg}), 500

@chatbot.route('/rag/status', methods=['GET'])
def rag_status():
    """Check collection status"""
    if collection:
        return jsonify({
            'status': 'active', 
            'count': collection.count(),
            'db_path': CHROMA_DB_PATH
        })
    return jsonify({'status': 'inactive', 'error': 'Collection not initialized'})
